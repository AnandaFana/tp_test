import numpy as np
import torch

import os
# from vllm import LLM, SamplingParams
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def analyze_and_visualize_logits(df_merged, tp1_name='TP1', tp2_name='TP2'):
    """
    åˆ†æå’Œå¯è§†åŒ–ä¸¤ä¸ªæ—¶é—´ç‚¹(TP1, TP2)ä¹‹é—´çš„logitså·®å¼‚

    Parameters:
    df_merged: åŒ…å«logitsæ•°æ®çš„DataFrame
    tp1_name: ç¬¬ä¸€ä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP1'
    tp2_name: ç¬¬äºŒä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP2'

    Returns:
    None (ç›´æ¥æ˜¾ç¤ºå›¾è¡¨å’Œæ‰“å°æŠ¥å‘Š)
    """
    import seaborn as sns
    import matplotlib.pyplot as plt

    # === 3. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ ===

    # A. è®¡ç®— Logits ç»å¯¹è¯¯å·® (æ•°å€¼å·®å¼‚)
    # æˆ‘ä»¬å¯¹æ¯” Top1_Logprob çš„å·®å¼‚
    df_merged['Logits_Diff'] = (df_merged[f'Top1_Logprob_{tp1_name}'] - df_merged[f'Top1_Logprob_{tp2_name}']).abs()

    # B. æ£€æŸ¥ Token ID æ˜¯å¦ç¿»è½¬ (æ’åºå·®å¼‚)
    # å¦‚æœ ID ä¸ä¸€æ ·ï¼Œè¯´æ˜å¾®å°çš„è¯¯å·®å¯¼è‡´æ¨¡å‹é€‰äº†ä¸åŒçš„è¯
    df_merged['Token_Mismatch'] = df_merged[f'Top1_ID_{tp1_name}'] != df_merged[f'Top1_ID_{tp2_name}']

    # C. ä¸ºäº†ç”»å›¾æ–¹ä¾¿ï¼Œåˆ›å»ºä¸€ä¸ªå…¨å±€çš„ Step è®¡æ•° (Global Step)
    df_merged['Global_Step'] = df_merged.index

    # === 4. å¯è§†åŒ–ç»˜å›¾ ===
    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(16, 10))

    # --- å›¾ 1: Logits è¯¯å·®æ•£ç‚¹å›¾ (The "Noise" Plot) ---
    plt.subplot(2, 1, 1)

    # ç”»æ•£ç‚¹ï¼Œé¢œè‰²æ ¹æ® Question_ID åŒºåˆ†
    scatter = sns.scatterplot(
        data=df_merged,
        x='Global_Step',
        y='Logits_Diff',
        hue='Question_ID',
        palette='tab10',
        s=60,
        alpha=0.7,
        edgecolor='w'
    )

    # å…³é”®ï¼šä½¿ç”¨å¯¹æ•°åæ ‡è½´ï¼Œå› ä¸ºè¯¯å·®é€šå¸¸æå°
    plt.yscale('log')

    plt.title(f' {tp1_name} vs {tp2_name} Logits Difference (Floating Point Error Analysis)', fontsize=15)
    plt.ylabel('Abs Difference (Log Scale)', fontsize=12)
    plt.xlabel('Token Sequence (Across all questions)', fontsize=12)
    plt.axhline(y=1e-5, color='r', linestyle='--', label='1e-5 Threshold')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title="Question ID")
    plt.grid(True, which="both", ls="--", alpha=0.3)

    plt.tight_layout()
    plt.show()

    # === 5. æ–‡å­—æŠ¥å‘Š ===
    print("====== ğŸ“ å®éªŒç»“æœåˆ†ææŠ¥å‘Š ======")
    print(f"æ€»è®¡åˆ†æ Token æ•°: {len(df_merged)}")
    print(f"æœ€å¤§ Logits è¯¯å·®: {df_merged['Logits_Diff'].max():.2e}")
    print(f"å¹³å‡ Logits è¯¯å·®: {df_merged['Logits_Diff'].mean():.2e}")
    print("-" * 30)

    mismatches = df_merged[df_merged['Token_Mismatch']]
    if len(mismatches) > 0:
        print(f"âš ï¸ è­¦å‘Š: å‘ç° {len(mismatches)} ä¸ª Token å‘ç”Ÿäº†é€‰æ‹©ç¿»è½¬ (Butterfly Effect)!")
        print("ç¿»è½¬è¯¦æƒ… (å‰5ä¸ª):")
        print(mismatches[['Question_ID', 'Step_Index', f'Top1_Text_{tp1_name}', f'Top1_Text_{tp2_name}', 'Logits_Diff']].head())
    else:
        print("âœ… å®Œç¾ä¸€è‡´: å°½ç®¡å­˜åœ¨æµ®ç‚¹è¯¯å·®ï¼Œä½† {} å’Œ {} é€‰æ‹©çš„ Token åºåˆ—å®Œå…¨ä¸€æ · (0 ç¿»è½¬)ã€‚".format(tp1_name, tp2_name))
        print("ç»“è®º: è¿™ç§å¾®å°çš„è¯¯å·® (Atomic Add å¯¼è‡´) æœªå½±å“ç”Ÿæˆç»“æœã€‚")

def compare_logprob_and_prob(df_merged, tp1_name='TP1', tp2_name='TP2'):
    """
    æ¯”è¾ƒä¸¤ä¸ªæ—¶é—´ç‚¹(TP1, TP2)ä¹‹é—´çš„logprobå’Œprobabilityå·®å¼‚

    Parameters:
    df_merged: åŒ…å«logitsæ•°æ®çš„DataFrame
    tp1_name: ç¬¬ä¸€ä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP1'
    tp2_name: ç¬¬äºŒä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP2'

    Returns:
    None (ç›´æ¥æ˜¾ç¤ºå›¾è¡¨å’Œæ‰“å°æŠ¥å‘Š)
    """
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np

    # ç¡®ä¿ df_merged è¿˜åœ¨å†…å­˜é‡Œï¼Œå¦‚æœä¸åœ¨è¯·é‡æ–°è¿è¡Œä¸Šä¸€æ®µçš„"è¯»å–"éƒ¨åˆ†
    if df_merged is None:
        print("è¯·å…ˆæä¾› df_merged æ•°æ®ï¼")
        return

    # 1. è®¡ç®—çº¿æ€§æ¦‚ç‡ (Probability = exp(Logprob))
    # è¿™ä»£è¡¨æ¨¡å‹è®¤ä¸ºè¿™ä¸ªè¯å‡ºç°çš„çœŸå®æ¦‚ç‡ (0% - 100%)
    df_merged[f'Prob_{tp1_name}'] = np.exp(df_merged[f'Top1_Logprob_{tp1_name}'])
    df_merged[f'Prob_{tp2_name}'] = np.exp(df_merged[f'Top1_Logprob_{tp2_name}'])

    # 2. ç»˜å›¾
    plt.figure(figsize=(16, 7))

    # --- å·¦å›¾: Logprob Scatter (å¯¹æ•°ç©ºé—´) ---
    plt.subplot(1, 2, 1)
    sns.scatterplot(
        x=f'Top1_Logprob_{tp1_name}',
        y=f'Top1_Logprob_{tp2_name}',
        data=df_merged,
        alpha=0.6,
        edgecolor=None,
        s=30,
        color='blue'
    )

    # ç”»ä¸€æ¡ y=x çš„çº¢çº¿ä½œä¸ºåŸºå‡†
    min_val = min(df_merged[f'Top1_Logprob_{tp1_name}'].min(), df_merged[f'Top1_Logprob_{tp2_name}'].min())
    max_val = max(df_merged[f'Top1_Logprob_{tp1_name}'].max(), df_merged[f'Top1_Logprob_{tp2_name}'].max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=1, label='Perfect Match (y=x)')

    plt.title(f'Log Space: {tp1_name} vs {tp2_name} (Logprobs)', fontsize=14)
    plt.xlabel(f'{tp1_name} Logprob (Values < 0)')
    plt.ylabel(f'{tp2_name} Logprob (Values < 0)')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # --- å³å›¾: Probability Scatter (çº¿æ€§ç©ºé—´) ---
    plt.subplot(1, 2, 2)
    sns.scatterplot(
        x=f'Prob_{tp1_name}',
        y=f'Prob_{tp2_name}',
        data=df_merged,
        alpha=0.6,
        edgecolor=None,
        s=30,
        color='green'
    )

    # ç”»ä¸€æ¡ y=x çš„çº¢çº¿
    plt.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Perfect Match (y=x)')

    plt.title(f'Linear Space: {tp1_name} vs {tp2_name} (Probabilities)', fontsize=14)
    plt.xlabel(f'{tp1_name} Probability (0.0 - 1.0)')
    plt.ylabel(f'{tp2_name} Probability (0.0 - 1.0)')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # ç®€å•çš„ç»Ÿè®¡
    print(f"Logprob ç›¸å…³ç³»æ•°: {df_merged[f'Top1_Logprob_{tp1_name}'].corr(df_merged[f'Top1_Logprob_{tp2_name}']):.8f}")
    print(f"Probability ç›¸å…³ç³»æ•°: {df_merged[f'Prob_{tp1_name}'].corr(df_merged[f'Prob_{tp2_name}']):.8f}")
    print()

    # è®¾ç½®ä¸€ä¸ªæå°å€¼é˜²æ­¢é™¤é›¶
    epsilon = 1e-9

    # === 1. è®¡ç®— MSE (å‡æ–¹è¯¯å·®) ===
    mse_logprob = ((df_merged[f'Top1_Logprob_{tp1_name}'] - df_merged[f'Top1_Logprob_{tp2_name}']) ** 2).mean()
    mse_prob    = ((df_merged[f'Prob_{tp1_name}'] - df_merged[f'Prob_{tp2_name}']) ** 2).mean()

    # === 2. è®¡ç®— Relative Error (ç›¸å¯¹è¯¯å·®) ===
    # å…¬å¼: |TP1 - TP2| / (|TP1| + epsilon)
    # Logprob ç©ºé—´
    rel_err_log = (df_merged[f'Top1_Logprob_{tp1_name}'] - df_merged[f'Top1_Logprob_{tp2_name}']).abs() / (df_merged[f'Top1_Logprob_{tp1_name}'].abs() + epsilon)
    # Probability ç©ºé—´
    rel_err_prob = (df_merged[f'Prob_{tp1_name}'] - df_merged[f'Prob_{tp2_name}']).abs

def calculate_error_metrics(df_merged, tp1_name='TP1', tp2_name='TP2'):
    """
    è®¡ç®—ä¸¤ä¸ªæ—¶é—´ç‚¹(TP1, TP2)ä¹‹é—´çš„è¯¯å·®æŒ‡æ ‡

    Parameters:
    df_merged: åŒ…å«logitsæ•°æ®çš„DataFrame
    tp1_name: ç¬¬ä¸€ä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP1'
    tp2_name: ç¬¬äºŒä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP2'

    Returns:
    dict: åŒ…å«å„ç§è¯¯å·®æŒ‡æ ‡çš„å­—å…¸
    """
    import numpy as np

    # è®¾ç½®ä¸€ä¸ªæå°å€¼é˜²æ­¢é™¤é›¶
    epsilon = 1e-9

    # === 1. è®¡ç®— MSE (å‡æ–¹è¯¯å·®) ===
    mse_logprob = ((df_merged[f'Top1_Logprob_{tp1_name}'] - df_merged[f'Top1_Logprob_{tp2_name}']) ** 2).mean()
    mse_prob    = ((df_merged[f'Prob_{tp1_name}'] - df_merged[f'Prob_{tp2_name}']) ** 2).mean()

    # === 2. è®¡ç®— Relative Error (ç›¸å¯¹è¯¯å·®) ===
    # å…¬å¼: |TP1 - TP2| / (|TP1| + epsilon)
    # Logprob ç©ºé—´
    rel_err_log = (df_merged[f'Top1_Logprob_{tp1_name}'] - df_merged[f'Top1_Logprob_{tp2_name}']).abs() / (df_merged[f'Top1_Logprob_{tp1_name}'].abs() + epsilon)
    # Probability ç©ºé—´
    rel_err_prob = (df_merged[f'Prob_{tp1_name}'] - df_merged[f'Prob_{tp2_name}']).abs() / (df_merged[f'Prob_{tp1_name}'] + epsilon)

    # === 3. æ ¼å¼åŒ–è¾“å‡º ===
    print(f"====== ğŸ“‰ è¯¯å·®ç»Ÿè®¡åˆ†æ (Metrics) ======")
    print(f"MSE (Logprobç©ºé—´):      {mse_logprob:.5e}")
    print(f"MSE (Probabilityç©ºé—´):  {mse_prob:.5e}")
    print("-" * 40)
    # print(f"å¹³å‡ç›¸å¯¹è¯¯å·® (Logprob):     {rel_err_log.mean():.6%}  (Max: {rel_err_log.max():.4%})")
    print(f"å¹³å‡ç›¸å¯¹è¯¯å·® (Probability): {rel_err_prob.mean():.6%}  (Max: {rel_err_prob.max():.4%})")

    # å¦‚æœä½ æƒ³çœ‹ç›¸å¯¹è¯¯å·®æœ€å¤§çš„å‰3ä¸ªæ ·æœ¬
    print(f"\n====== âš ï¸ ç›¸å¯¹è¯¯å·®(Prob)æœ€å¤§çš„ Top 3 æ ·æœ¬ ======")
    df_merged['Rel_Err_Prob_Val'] = rel_err_prob
    top_errors = df_merged.nlargest(3, 'Rel_Err_Prob_Val')
    for i, row in top_errors.iterrows():
        print(f"ID: {row['Question_ID']} | Token: {row[f'Top1_Text_{tp1_name}']} | {tp1_name}_Prob: {row[f'Prob_{tp1_name}']:.4f} | {tp2_name}_Prob: {row[f'Prob_{tp2_name}']:.4f} | Err: {row['Rel_Err_Prob_Val']:.2%}")

    # è¿”å›è¯¯å·®æŒ‡æ ‡å­—å…¸
    return {
        'mse_logprob': mse_logprob,
        'mse_prob': mse_prob,
        'mean_rel_err_log': rel_err_log.mean(),
        'max_rel_err_log': rel_err_log.max(),
        'mean_rel_err_prob': rel_err_prob.mean(),
        'max_rel_err_prob': rel_err_prob.max(),
        'rel_err_log': rel_err_log,
        'rel_err_prob': rel_err_prob
    }

def analyze_divergence_tracking(df_merged, tp1_name='TP1', tp2_name='TP2'):
    """
    åˆ†æä¸¤ä¸ªæ—¶é—´ç‚¹(TP1, TP2)ä¹‹é—´çš„è·¯å¾„åç¦»æƒ…å†µ

    Parameters:
    df_merged: åŒ…å«logitsæ•°æ®çš„DataFrame
    tp1_name: ç¬¬ä¸€ä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP1'
    tp2_name: ç¬¬äºŒä¸ªæ—¶é—´ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º'TP2'

    Returns:
    dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    import pandas as pd

    # ==========================================
    # 1. æ ¸å¿ƒé€»è¾‘ï¼šè¯†åˆ«å¹¶æ ‡è®°"åˆ†æ°´å²­" (Divergence Tracking)
    # ==========================================

    # A. è®¡ç®—å•ç‚¹ Token æ˜¯å¦ä¸åŒ¹é…
    df_merged['Token_Mismatch'] = df_merged[f'Top1_ID_{tp1_name}'] != df_merged[f'Top1_ID_{tp2_name}']

    # B. è®¡ç®—åˆ†æ°´å²­çŠ¶æ€ (Is_Diverged)
    # é€»è¾‘ï¼šå¯¹äºæ¯ä¸ªé—®é¢˜ï¼Œä¸€æ—¦å‡ºç°è¿‡ Mismatchï¼Œåç»­æ‰€æœ‰ Token éƒ½æ ‡è®°ä¸º Diverged
    df_merged['Is_Diverged'] = False

    for q_id in df_merged['Question_ID'].unique():
        # è·å–å½“å‰é—®é¢˜çš„æ©ç 
        q_mask = df_merged['Question_ID'] == q_id
        q_data = df_merged[q_mask].sort_values('Step_Index')

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸åŒ¹é…çš„ç´¢å¼•
        mismatch_steps = q_data[q_data['Token_Mismatch']]['Step_Index']

        if not mismatch_steps.empty:
            first_mismatch_step = mismatch_steps.min()
            # å°†è¯¥ step åŠå…¶ä¹‹åçš„ token å…¨éƒ¨æ ‡è®°ä¸ºå·²åç¦»
            df_merged.loc[q_mask & (df_merged['Step_Index'] >= first_mismatch_step), 'Is_Diverged'] = True

    # åˆ›å»ºå¯è¯»çš„çŠ¶æ€æ ‡ç­¾ç”¨äºç»˜å›¾
    df_merged['Diverge_Status'] = df_merged['Is_Diverged'].map({False: 'Consistent (Pre-diverge)', True: 'Diverged (Post-diverge)'})

    # ==========================================
    # 2. é‡æ–°è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ (Metrics)
    # ==========================================

    # è®¡ç®—æ¦‚ç‡ç©ºé—´å€¼
    df_merged[f'Prob_{tp1_name}'] = np.exp(df_merged[f'Top1_Logprob_{tp1_name}'])
    df_merged[f'Prob_{tp2_name}'] = np.exp(df_merged[f'Top1_Logprob_{tp2_name}'])
    df_merged['Logits_Diff'] = (df_merged[f'Top1_Logprob_{tp1_name}'] - df_merged[f'Top1_Logprob_{tp2_name}']).abs()

    # åˆ†ç»„è®¡ç®—æŒ‡æ ‡ï¼šæˆ‘ä»¬ä¸»è¦å…³æ³¨"ä¸€è‡´é˜¶æ®µ"çš„å¾®å°è¯¯å·®
    stats_consistent = df_merged[~df_merged['Is_Diverged']]
    stats_diverged = df_merged[df_merged['Is_Diverged']]

    # ==========================================
    # 3. å¯è§†åŒ–ç»˜å›¾ (Improved Scatter Plot)
    # ==========================================

    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(18, 8))

    # --- å³å›¾ (æŒ‰æ‚¨çš„è¦æ±‚ä¿®æ”¹çš„ Prob æ•£ç‚¹å›¾) ---
    plt.subplot(1, 2, 1)

    # ä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ä¸€è‡´å‰å’Œå·®åˆ«å
    # ç»¿è‰²ä»£è¡¨è·¯å¾„ä¸€è‡´æ—¶çš„å¾®å°æµ®ç‚¹è¯¯å·®ï¼Œçº¢è‰²ä»£è¡¨è·¯å¾„åˆ†å‰åçš„å·¨å¤§å·®å¼‚
    palette_colors = {"Consistent (Pre-diverge)": "#2ecc71", "Diverged (Post-diverge)": "#e74c3c"}

    sns.scatterplot(
        x=f'Prob_{tp1_name}',
        y=f'Prob_{tp2_name}',
        hue='Diverge_Status',
        data=df_merged,
        palette=palette_colors,
        alpha=0.6,
        edgecolor=None,
        s=40
    )

    # ç”»ä¸€æ¡ y=x çš„å¯¹è§’çº¿
    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, linewidth=1, label='Perfect Match (y=x)')

    plt.title(f'Probability Distribution: {tp1_name} vs {tp2_name} (Pre vs Post Divergence)', fontsize=15)
    plt.xlabel(f'{tp1_name} Probability', fontsize=12)
    plt.ylabel(f'{tp2_name} Probability', fontsize=12)
    plt.legend(title="Generation Status")

    # --- å·¦å›¾: Logits éšæ—¶é—´çš„å˜åŒ– (æ˜¾ç¤ºè¯¯å·®ç§¯ç´¯) ---
    plt.subplot(1, 2, 2)
    sns.scatterplot(
        x=df_merged.index,
        y='Logits_Diff',
        hue='Diverge_Status',
        data=df_merged,
        palette=palette_colors,
        s=40,
        alpha=0.7
    )
    plt.yscale('log') # å¯¹æ•°åæ ‡æ›´æ˜“è§‚å¯Ÿ 1e-6 çº§åˆ«çš„è¯¯å·®
    plt.axhline(y=1e-5, color='blue', linestyle=':', label='Common Float16 Noise Threshold')
    plt.title('Logits Absolute Difference (Temporal View)', fontsize=15)
    plt.ylabel('Abs Diff (Log Scale)', fontsize=12)
    plt.xlabel('Global Token Sequence', fontsize=12)
    plt.legend()

    plt.tight_layout()
    plt.show()

    # ==========================================
    # 4. è¯¦ç»†æŒ‡æ ‡æŠ¥å‘Š
    # ==========================================
    print(f"      ====== ğŸ“Š {tp1_name} vs {tp2_name} æ·±åº¦å·®å¼‚æŠ¥å‘Š ======      ")
    print(f"æ€»åˆ†æ Token æ•°: {len(df_merged)}")
    print(f"å‘ç”Ÿè·¯å¾„åç¦»çš„ Token æ•°: {len(stats_diverged)} (å  {len(stats_diverged)/len(df_merged):.2%})")
    print("-" * 50)

    print(f"ã€é˜¶æ®µ A: è·¯å¾„ä¸€è‡´æ—¶ (Consistent)ã€‘")
    if not stats_consistent.empty:
        print(f" -> å¹³å‡ Logits è¯¯å·®: {stats_consistent['Logits_Diff'].mean():.2e}")
        print(f" -> æœ€å¤§ Logits è¯¯å·®: {stats_consistent['Logits_Diff'].max():.2e}")
        print(f" -> MSE (Probability): {((stats_consistent[f'Prob_{tp1_name}'] - stats_consistent[f'Prob_{tp2_name}'])**2).mean():.2e}")
    else:
        print(" -> (æ— æ•°æ®)")

    print(f"\nã€é˜¶æ®µ B: è·¯å¾„åç¦»å (Diverged)ã€‘")
    if not stats_diverged.empty:
        print(f" -> å¹³å‡ Logits è¯¯å·®: {stats_diverged['Logits_Diff'].mean():.2e} (ç”±äºè¾“å…¥ä¸åŒï¼Œè¯¯å·®å¤©ç„¶å˜å¤§)")
        print(f" -> è·¯å¾„åç¦»çš„é¦–ä¸ª ID ç¤ºä¾‹:")
        first_diffs = df_merged[df_merged['Token_Mismatch']].groupby('Question_ID').first()
        print(first_diffs[[f'Top1_Text_{tp1_name}', f'Top1_Text_{tp2_name}', 'Logits_Diff']].head())
    else:
        print(f" -> âœ… æ­å–œï¼šæ‰€æœ‰æ ·æœ¬è·¯å¾„å®Œå…¨ä¸€è‡´ï¼Œæœªå‘ç”Ÿ Divergenceã€‚")

    print("-" * 50)

    # è¿”å›åˆ†æç»“æœå­—å…¸
    return {
        'stats_consistent': stats_consistent,
        'stats_diverged': stats_diverged,
        'total_tokens': len(df_merged),
        'diverged_tokens': len(stats_diverged),
        'divergence_ratio': len(stats_diverged)/len(df_merged) if len(df_merged) > 0 else 0,
        'mean_logits_diff_consistent': stats_consistent['Logits_Diff'].mean() if not stats_consistent.empty else 0,
        'max_logits_diff_consistent': stats_consistent['Logits_Diff'].max() if not stats_consistent.empty else 0,
        'mse_prob_consistent': ((stats_consistent[f'Prob_{tp1_name}'] - stats_consistent[f'Prob_{tp2_name}'])**2).mean() if not stats_consistent.empty else 0
    }

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
from sklearn.metrics.pairwise import cosine_similarity
from typing import Dict, List, Optional

# ==========================================
# å‡½æ•° 1: æå– .json æ–‡ä»¶ä¸ºå­—å…¸
# ==========================================
def load_debug_json(filepath: str) -> Dict[int, dict]:
    """
    è¯»å– JSONL æ ¼å¼çš„æ–‡ä»¶ï¼Œå¹¶æŒ‰ index ç»„ç»‡æˆå­—å…¸ã€‚

    Args:
        filepath: JSON æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚ 'layer_13_post_attn_tp1.json')
    Returns:
        Dict: { index: { 'shape': list, 'data': np.array } }
    """
    data_map = {}
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            entry = json.loads(line)
            idx = entry['index']
            # å°†åˆ—è¡¨è½¬æ¢ä¸º numpy æ•°ç»„ä»¥ä¾¿åç»­è®¡ç®—ï¼ŒåŒæ—¶ä¿æŒåŸå§‹ç»´åº¦
            data_map[idx] = {
                'shape': entry['shape'],
                'data': np.array(entry['data'], dtype=np.float32)
            }
    print(f"[Loader] æˆåŠŸåŠ è½½ {filepath}, åŒ…å« {len(data_map)} ä¸ª Step æ•°æ®ã€‚")
    return data_map

# ==========================================
# å‡½æ•° 2: æ¯”è¾ƒä¸åŒé…ç½®ä¹‹é—´çš„ç›¸ä¼¼åº¦
# ==========================================
def compare_tp_configs(dict_ref: Dict[int, dict], dict_target: Dict[int, dict]) -> pd.DataFrame:
    """
    æ¯”è¾ƒä¸¤ä¸ªå­—å…¸ä¸­ç›¸åŒ index å’Œ shape çš„æ•°æ®ç›¸ä¼¼åº¦ã€‚
    ä½¿ç”¨ä¸‰ç§æŒ‡æ ‡ï¼šCosine Similarity, Pearson Correlation, MSE (å‡æ–¹è¯¯å·®)ã€‚

    Returns:
        pd.DataFrame: åŒ…å« Index, Shape, å„é¡¹æŒ‡æ ‡çš„ Mean/Max/Min
    """
    results = []

    # è·å–äº¤é›†ç´¢å¼•å¹¶æ’åº
    common_indices = sorted(set(dict_ref.keys()) & set(dict_target.keys()))

    for idx in common_indices:
        data1 = dict_ref[idx]['data']
        data2 = dict_target[idx]['data']
        shape1 = dict_ref[idx]['shape']
        shape2 = dict_target[idx]['shape']

        # 1. æ£€æŸ¥ Shape æ˜¯å¦ä¸€è‡´ (å¦‚æœä¸ä¸€è‡´ï¼Œé€šå¸¸æ˜¯ prefill/decode é˜¶æ®µä¸å¯¹åº”ï¼Œè·³è¿‡)
        if shape1 != shape2:
            continue

        # å°†æ•°æ®å±•å¹³ä¸º [N, D] å½¢å¼ï¼Œå…¶ä¸­ D æ˜¯æœ€åä¸€ä¸ªç»´åº¦ï¼ˆHidden Dimï¼‰
        # å¦‚æœæ˜¯ [10, 2048]ï¼Œåˆ™ N=10, D=2048
        v1 = data1.reshape(-1, data1.shape[-1])
        v2 = data2.reshape(-1, data2.shape[-1])

        cos_list, pearson_list, mse_list = [], [], []

        # 2. é€å‘é‡è®¡ç®— (ä»¥ 2048 ç»´åº¦ä¸ºä¾‹)
        for i in range(v1.shape[0]):
            vec1 = v1[i].reshape(1, -1)
            vec2 = v2[i].reshape(1, -1)

            # æŒ‡æ ‡ A: ä½™å¼¦ç›¸ä¼¼åº¦
            cos = cosine_similarity(vec1, vec2)[0][0]
            cos_list.append(cos)

            # æŒ‡æ ‡ B: Pearson ç›¸å…³ç³»æ•°
            # pearsonr è¿”å› (correlation, p-value)ï¼Œç”±äºæ˜¯æµ®ç‚¹å¯¹æ¯”ï¼Œé‡ç‚¹åœ¨ correlation
            corr, _ = pearsonr(v1[i], v2[i])
            pearson_list.append(corr)

            # æŒ‡æ ‡ C: MSE (å‡æ–¹è¯¯å·®) - ååº”æ•°å€¼ç»å¯¹åå·®
            mse = np.mean((v1[i] - v2[i])**2)
            mse_list.append(mse)

        # 3. æ±‡æ€»å½“å‰ Step çš„æŒ‡æ ‡
        results.append({
            'index': idx,
            'shape': str(shape1),
            'cos_mean': np.mean(cos_list),
            'cos_max': np.max(cos_list),
            'cos_min': np.min(cos_list),
            'pearson_mean': np.mean(pearson_list),
            'pearson_max': np.max(pearson_list),
            'pearson_min': np.min(pearson_list),
            'mse_mean': np.mean(mse_list),
            'mse_max': np.max(mse_list)
        })

    df = pd.DataFrame(results)
    return df

# ==========================================
# å‡½æ•° 3: ç»˜åˆ¶ç›¸ä¼¼åº¦å˜åŒ–æ›²çº¿
# ==========================================
def plot_similarity_report(df: pd.DataFrame, metric_type: str = 'cos', title: str = "TP Consistency Analysis", plot_min_max: bool = True):
    """
    ç»˜åˆ¶æŒ‡å®šæŒ‡æ ‡éš Index å˜åŒ–çš„è¶‹åŠ¿å›¾ã€‚

    Args:
        df: compare_tp_configs ç”Ÿæˆçš„ DataFrame
        metric_type: 'cos', 'pearson', æˆ– 'mse'
    """
    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(14, 7))

    # æ˜ å°„åˆ—å
    prefix = metric_type.lower()
    col_mean = f"{prefix}_mean"
    col_max = f"{prefix}_max"
    col_min = f"{prefix}_min"

    if col_mean not in df.columns:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æŒ‡æ ‡ {metric_type}")
        return

    # ç»˜åˆ¶å‡å€¼æ›²çº¿
    plt.plot(df['index'], df[col_mean], color='#1f77b4', label=f'Mean {metric_type.upper()}', linewidth=2, marker='o', markersize=4)

    # ç»˜åˆ¶æœ€å¤§/æœ€å°å€¼å¡«å……åŒºé—´ (Shaded Area)
    if col_min in df.columns and plot_min_max:
        plt.fill_between(df['index'], df[col_min], df[col_max], color='#1f77b4', alpha=0.2, label='Max-Min Range')

    # æ·»åŠ æ‹Ÿåˆæ›²çº¿ (Polynomial Fit)
    z = np.polyfit(df['index'], df[col_mean], 3)
    p = np.poly1d(z)
    plt.plot(df['index'], p(df['index']), "r--", alpha=0.8, label='Trend')

    # ç¾åŒ–å›¾è¡¨
    plt.title(f'{title}: {metric_type.upper()} over Steps', fontsize=16)
    plt.xlabel('Token Generation Step (Index)', fontsize=12)
    plt.ylabel(f'Similarity Metric ({metric_type.upper()})', fontsize=12)

    # å¦‚æœæ˜¯ Cosine æˆ– Pearsonï¼Œå›ºå®š Y è½´èŒƒå›´åœ¨ [0, 1.05] æ–¹ä¾¿è§‚å¯Ÿ
    if metric_type in ['cos', 'pearson'] and plot_min_max:
        current_min = df[col_min].min()
        plt.ylim(max(0, current_min - 0.05), 1.05)

    plt.legend(loc='best')
    plt.tight_layout()
    plt.show()


